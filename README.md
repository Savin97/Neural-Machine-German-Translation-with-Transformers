# Transformer-based Neural Machine Translation (English â†” German)

This project implements a **Transformer-based sequence-to-sequence neural machine translation** model trained on the **Multi30k Englishâ€“German dataset**. It follows the *"Attention Is All You Need"* architecture, leveraging **multi-head self-attention** for efficient and accurate translation.

## ðŸ“Œ Overview

* **Frameworks:** PyTorch, TorchText, SpaCy
* **Architecture:** Encoderâ€“Decoder with multi-head self-attention (`nn.Transformer`)
* **Task:** English â†” German translation
* **Evaluation:** BLEU score & qualitative translation analysis

## ðŸš€ Features

* Tokenization and preprocessing of the Multi30k bilingual dataset using SpaCy
* Subword vocabulary creation for robust handling of rare words and morphology
* Implementation of Transformer encoderâ€“decoder in PyTorch with positional encoding
* Hyperparameter tuning: batch size, embedding dimension, learning rate, layers, attention heads
* Model evaluation with BLEU and human-readable translation samples

## ðŸ“‚ Project Structure

```
â”œâ”€â”€ data/                  # Dataset loading & preprocessing scripts
â”œâ”€â”€ model/                 # Transformer model definition
â”œâ”€â”€ train.py               # Training loop
â”œâ”€â”€ evaluate.py            # Evaluation scripts
â”œâ”€â”€ utils.py               # Helper functions (masks, tokenization, vocab)
â”œâ”€â”€ outputs/               # Sample translations & BLEU scores
â””â”€â”€ README.md              # Project documentation
```

## ðŸ“Š Example Outputs

| Input (DE)                                                         | Output (EN)                                                           |
| ------------------------------------------------------------------ | --------------------------------------------------------------------- |
| ein mann in einem blauen hemd steht auf der seite eines gebÃ¤udes . | Skateboarder in a blue bathing suit standing on the edge of a house . |
| zwei mÃ¤nner in einem restaurant unterhalten sich .                 | 2 friends are talking to each other in a restaurant .                 |
| ein kind spielt mit einem ball auf einem groÃŸen feld .             | Surfer is playing with a large board on a large surface .             |

*(Note: Translation quality limited by small dataset size! Improvements discussed below.)*

## ðŸ”§ Future Improvements

* Add **padding masks** for source, target, and memory to improve alignment
* Use **subword tokenization** (SentencePiece/BPE) to reduce rare-word errors
* Apply **label smoothing**, **Noam learning rate warm-up**, and **gradient clipping** for more stable training
* Implement **length-penalized beam search** to reduce repetitive or irrelevant phrases

## ðŸ“œ References

* Vaswani et al., *Attention Is All You Need*, 2017
* [PyTorch `nn.Transformer` Documentation](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)
* [TorchText Multi30k Dataset](https://pytorch.org/text/stable/datasets.html#multi30k)
